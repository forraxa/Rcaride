<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
      <title>
        Rcaride
      </title>
      <!-- Always force latest IE rendering engine (even in intranet) & Chrome Frame -->
      <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible"/>
      <meta content="width=device-width, initial-scale=1.0" name="viewport">
        <meta content="Rcaride apuntes" name="description"/>
        <meta content="R, Rstudio, spark, hadoop, mongodb, datawarehouse, pentaho, python, big data, machine learning" name="keywords"/>
        <meta content="Roberto Caride" name="author"/>
        <!-- <link rel="publisher" href="https://plus.google.com/117689250782136016574"> -->
        <!-- Le styles -->
        <link href="http://fonts.googleapis.com/css?family=Roboto:400,300,700" rel="stylesheet" type="text/css">
          <link href="assets/css/font-awesome.min.css" rel="stylesheet">
            <!--[if IE 7]>
      <link rel="stylesheet" href="assets/css/font-awesome-ie7.min.css">
      <![endif]-->
            <link href="assets/css/bootplus.css" rel="stylesheet">
              <link href="assets/css/bootplus-responsive.css" rel="stylesheet">
                <link href="assets/css/docs.css" rel="stylesheet">
                  <link href="assets/js/google-code-prettify/prettify.css" rel="stylesheet">
                    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
                    <!--[if lt IE 9]>
        <script src="assets/js/html5shiv.js"></script>
      <![endif]-->
                    <!-- Le fav and touch icons -->
                    <link href="assets/ico/apple-touch-icon-144-precomposed.png" rel="apple-touch-icon-precomposed" sizes="144x144">
                      <link href="assets/ico/apple-touch-icon-114-precomposed.png" rel="apple-touch-icon-precomposed" sizes="114x114">
                        <link href="assets/ico/apple-touch-icon-72-precomposed.png" rel="apple-touch-icon-precomposed" sizes="72x72">
                          <link href="assets/ico/apple-touch-icon-57-precomposed.png" rel="apple-touch-icon-precomposed">
                            <link href="assets/ico/favicon.png" rel="shortcut icon">
                              <script type="text/javascript">
                                var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-3182578-9']);
        _gaq.push(['_trackPageview']);

        (function() {
          var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
          ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
          var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
                              </script>
                            </link>
                          </link>
                        </link>
                      </link>
                    </link>
                  </link>
                </link>
              </link>
            </link>
          </link>
        </link>
      </meta>
    </meta>
  </head>
  <body data-spy="scroll" data-target=".bs-docs-sidebar">
    <!-- Navbar
    ================================================== -->
    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <button class="btn btn-navbar" data-target=".nav-collapse" data-toggle="collapse" type="button">
            <span class="icon-bar">
            </span>
            <span class="icon-bar">
            </span>
            <span class="icon-bar">
            </span>
          </button>
          <a class="brand" href="./index.html">
            Rcaride
          </a>
          <div class="nav-collapse collapse">
            <ul class="nav">
              <li class="active">
                <a href="./index.html">
                  Inicio
                </a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
    <!-- Subhead
================================================== -->
    <header class="jumbotron subhead masthead" id="overview">
      <div class="container">
        <h1>
          Apuntes, análisis y proyectos
        </h1>
        <p class="lead">
          R, spark, hadoop, mongodb, datawarehouse, pentaho, python, big data, machine learning...
        </p>
      </div>
    </header>
    <div class="container">
      <!-- Docs nav
    ================================================== -->
      <div class="row">
        <div class="span3 bs-docs-sidebar">
          <ul class="nav nav-list bs-docs-sidenav">
            <li>
              <a href="#fundamentos-head">
                1. Fundamentos
              </a>
            </li>
            <li>
              <a href="#instalacion-head">
                2. Instalación
              </a>
            </li>
            <li>
              <a href="#rdd-dataframe">
                3. RDD
              </a>
            </li>
            <li>
              <a href="#transformaciones">
                4. Transformaciones
              </a>
            </li>
            <li>
              <a href="#acciones">
                5. Acciones
              </a>
            </li>
            <li>
              <a href="#persistencia-head">
                6. Persistencia y acumuluadores
              </a>
            </li>
            <li>
              <a href="#dataframe-dataset">
                7. Dataframe y Dataset
              </a>
            </li>
            <li>
              <a href="#vistas">
                8. Vistas
              </a>
            </li>
          </ul>
        </div>
        <div class="span9">
          <!-- Fundamentos
        ================================================== -->
          <section id="fundamentos-head">
            <div class="page-header">
              <h1>
                1. Fundamentos
              </h1>
            </div>
            <p class="lead">
              SPARK: Sistema de computación de datos.
            </p>
            <ul>
              <li>
                Se integra a la perfección con Hadoop
              </li>
              <li>
                Trabaja en memoria y disco aunque su máximo rendimiento lo obtiene en memoria, hasta 100 veces más rápido
              </li>
              <li>
                Tiene API Java, Python, Scala, R
              </li>
              <li>
                Spark permite el procesamiento en casi tiempo real (mini batch)
              </li>
              <li>
                <strong>
                  RDD:
                </strong>
                Resilient Distributed Dataset.
                <p>
                  Son los datos distribuidos en memoria
                </p>
              </li>
              <li>
                Usa evaluación perezosa.
                <p>
                  No ejecuta el código en las transformación, sólo en las acciones sobre los datos
                </p>
              </li>
            </ul>
            <hr>
              <p class="lead">
                Componentes principales.
              </p>
              <ul>
                <li>
                  Spark Core: Base donde se apoyan los demás componentes
                </li>
                <li>
                  Spark SQL: Procesamiento de datos estructurados y semi-estructurados
                </li>
                <li>
                  Spark Streaming: Procesamineto de datos en tiempo casi real
                </li>
                <li>
                  Spark MLlib (machine learning): Librería de Machine Learning
                </li>
                <li>
                  Spark GraphX: Procesamineto de grafos.
                  <p>
                    DAG: Grafo asíncrono dirigido
                  </p>
                </li>
              </ul>
              <img alt="" src="assets/img/spark-stack.png"/>
              <hr>
                <p class="lead">
                  Arquitectura de Spark
                </p>
                <img alt="" src="assets/img/arquitectura-spark.png"/>
                <hr>
                  <p class="lead">
                    SparkContext
                  </p>
                  <p>
                    Es el objeto que especifica como vamos a acceder a nuestro cluster
                  </p>
                  <p>
                    Es el contexto donde se crean las variables en Spark
                  </p>
                  <p>
                    Se instancia con la variable "sc" (no todos los entornos)
                  </p>
                  <p>
                    La creación de un objeto
                    <strong>
                      SparkContext
                    </strong>
                    lleva implicitamente un objeto
                    <strong>
                      SparkConf
                    </strong>
                  </p>
                  <hr>
                    <p class="lead">
                      SparkConf
                    </p>
                    <p>
                      Este objeto contien la información sobre nuestra aplicación.
                    </p>
                    <hr>
                      <p class="lead">
                        Cluster Manager - Gestores de recursos.
                      </p>
                      <ul>
                        <li>
                          <strong>
                            Standalone:
                          </strong>
                          Viene incluido en Spark (es muy sencillo)
                        </li>
                        <li>
                          <strong>
                            Mesos:
                          </strong>
                          Gestor de recursos de Spark, puede ejecutar Hadoop, Map Reduce y aplicaciones de servicio
                        </li>
                        <li>
                          <strong>
                            YARN:
                          </strong>
                          Gestor de recursos propio de Hadoop 2, puede ser utilizado por SPARK
                        </li>
                      </ul>
                      <hr>
                        <p class="lead">
                          Executors
                        </p>
                        <p>
                          Son los encargados de ejecutar las
                          <strong>
                            tareas o task
                          </strong>
                          en los nodos del cluster a petición del
                          <strong>
                            Cluster Manager
                          </strong>
                        </p>
                        <hr>
                          <p class="lead">
                            RDD Resilient Distributed Datasets
                          </p>
                          <p>
                            Conjunto de datos distribuidos en memoria donde la memoria está configurada a modo de un cluster por lo que el tratamiento de los datos se realiza de forma paralela, rápida y tolerante a fallos.
                          </p>
                          <h4>
                            Tipos de RDD según su origen:
                          </h4>
                          <ul>
                            <li>
                              <strong>
                                Colecciones paralelizadas:
                              </strong>
                              basadas en colecciones de Scala
                            </li>
                            <li>
                              <strong>
                                Datasets de Hadoop:
                              </strong>
                              creados a partir de ficheros almacenados en HDFS.
                            </li>
                          </ul>
                          <h4>
                            Tipos de operaciones sobre un RDD:
                          </h4>
                          <ul>
                            <li>
                              <strong>
                                Transformaciones:
                              </strong>
                              Crean nuevos conjutos de datos
                            </li>
                            <ul>
                              <li>
                                <strong>
                                  Narrow:
                                </strong>
                                Las transformaciones se han de realizar mezclando distintas particiones.
                                <p>
                                  filter(), sample(), map(), flatmap()
                                </p>
                              </li>
                              <li>
                                <strong>
                                  Wide:
                                </strong>
                                Las transformaciones se realizan en la su propia partición.
                                <p>
                                  groupByKey(), reduceByKey()
                                </p>
                              </li>
                            </ul>
                            <li>
                              <strong>
                                Acciones:
                              </strong>
                              Devuelven el valor al driver del cluster tras realizar un computo sobre los datos.
                              <p>
                                reduce(), collect(), count(), first(), take()
                              </p>
                            </li>
                          </ul>
                        </hr>
                      </hr>
                    </hr>
                  </hr>
                </hr>
              </hr>
            </hr>
          </section>
          <!-- Instalación
        ================================================== -->
          <section id="instalacion-head">
            <div class="page-header">
              <h1>
                2. Instalación
              </h1>
            </div>
            <p class="lead">
              3 modalidades de instalación.
            </p>
            <ul>
              <li>
                <strong>
                  Standalone:
                </strong>
                <p>
                  Spark + HDFS
                </p>
              </li>
              <li>
                <strong>
                  Hadoop V1:
                </strong>
                <p>
                  Spark + Map Reduce + HDFS
                </p>
              </li>
              <li>
                <strong>
                  Hadoop V2:
                </strong>
                <p>
                  Spark + YARN/Mesos + HDFS
                </p>
              </li>
            </ul>
            <hr>
              <p class="lead">
                Instalación de Standalone.
              </p>
              <p>
                Se instalará a partir de una Máquina Virtual de 64bits con Ubuntu 16.04.
              </p>
              <p>
                La máquina incluye:
              </p>
              <ul>
                <li>
                  Apache Spark 2.2
                </li>
                <li>
                  Python 3.5.2
                </li>
                <li>
                  Jupyter Notebook
                </li>
                <li>
                  Notebook Spark con Kernel para Python 3.5, Scala (SPylon) y R (IRKernel)
                </li>
              </ul>
              <p>
                Para instalar la VM se necesita:
              </p>
              <ul>
                <li>
                  <a href="https://www.virtualbox.org/">
                    Virtualbox
                  </a>
                  5.0 o superior.
                </li>
                <li>
                  <a href="https://www.vagrantup.com/">
                    Vagrant
                  </a>
                  1.8 o superior.
                </li>
              </ul>
              <hr>
                <p class="lead">
                  Proceso de instalación.
                </p>
                <ol>
                  <li>
                    <p>
                      Clonar o descargar la máquina Virtual,
                      <a href="https://github.com/paulovn/ml-vm-notebook">
                        Descargar
                      </a>
                    </p>
                  </li>
                  <li>
                    Abrir un terminal y situarnos dentro de la carpeta donde hayamos descomprimido la máquina virtual, dentro de la carpeta encontraremos el fichero
                    <strong>
                      Vagrantfile
                    </strong>
                  </li>
                  <li>
                    Ejecutamos
                    <strong>
                      vagrant up
                    </strong>
                    para levantar la máquina
                    <p>
                      Esto preparará la máquina virtual y lanzará el notebook de Jupyter en el puerto 8008.
                    </p>
                    <p>
                      La contraseña para entrar es "
                      <strong>
                        vmuser
                      </strong>
                      "
                    </p>
                  </li>
                </ol>
                <p>
                  <strong>
                    vagrant halt
                  </strong>
                  pausa la VM
                </p>
                <p>
                  <strong>
                    vagrant destroy
                  </strong>
                  Elimina la instalación de la VM
                </p>
                <p>
                  Editar
                  <strong>
                    vagrantfile
                  </strong>
                  para modificar la configuración de la VM
                </p>
                <p>
                  <strong>
                    vagrant ssh
                  </strong>
                  para acceso a un terminal de la VM
                </p>
                <hr>
                  <p>
                    <strong>
                      http://localhost:8008
                    </strong>
                    para acceder al notebook
                  </p>
                  <p>
                    <strong>
                      http://localhost:4040/
                    </strong>
                    para monitorizar los jobs lanzados en Spark
                  </p>
                </hr>
              </hr>
            </hr>
          </section>
          <!-- RDD, Dataframe y Dataset
        ================================================== -->
          <section id="rdd-dataframe">
            <div class="page-header">
              <h1>
                3. RDD
              </h1>
            </div>
            <p>
              Los RDD son los datos que se han leido y se han particionado en los nodos del cluster que se crea en la memoria
            </p>
            <p>
              Los orígenes de los datos pueden ser diversos pero una fuente de datos muy común es HDFS
            </p>
            <p>
              Contra los RDD se pueden lanzar:
            </p>
            <ul>
              <li>
                <strong>
                  Transformaciones:
                </strong>
                Crea un nuevo RDD a partir de otro existente
              </li>
              <li>
                <strong>
                  Acciones:
                </strong>
                Genera un valor que es mandado al
                <strong>
                  driver
                </strong>
              </li>
            </ul>
            <div class="row">
              <div class="span4">
                <div class="row">
                  <p style="margin-left:30px">
                    <strong>
                      Transformaciones:
                    </strong>
                  </p>
                  <div class="span1">
                    <ul>
                      <li>
                        map
                      </li>
                      <li>
                        filter
                      </li>
                      <li>
                        flatMap
                      </li>
                      <li>
                        union
                      </li>
                      <li>
                        intersection
                      </li>
                      <li>
                        distinct
                      </li>
                    </ul>
                  </div>
                  <div class="span1">
                    <ul>
                      <li>
                        groupByKey
                      </li>
                      <li>
                        reduceByKey
                      </li>
                      <li>
                        sortByKey
                      </li>
                      <li>
                        join
                      </li>
                      <li>
                        cogroup
                      </li>
                      <li>
                        coalesce
                      </li>
                    </ul>
                  </div>
                </div>
              </div>
              <div class="span4">
                <div class="row">
                  <p>
                    <strong>
                      Acciones:
                    </strong>
                  </p>
                  <div class="span1">
                    <ul>
                      <li>
                        reduce
                      </li>
                      <li>
                        collect
                      </li>
                      <li>
                        count
                      </li>
                      <li>
                        first
                      </li>
                      <li>
                        take
                      </li>
                    </ul>
                  </div>
                  <div class="span1">
                    <ul>
                      <li>
                        saveAsTextFile
                      </li>
                      <li>
                        max, min...
                      </li>
                      <li>
                        countByKey
                      </li>
                      <li>
                        foreach
                      </li>
                    </ul>
                  </div>
                </div>
              </div>
            </div>
            <hr>
              <p>
                Creación de RDDs:
              </p>
              <div class="codigo-scala">
                <div class="border-box-sizing" id="notebook" tabindex="-1">
                  <div id="notebook-container">
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [1]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//importamos SparkConf, SparkContext, RDD</span>
<span class="k">import</span> <span class="nn">org.apache.spark.SparkConf</span> 
<span class="k">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="output_wrapper">
                        <div class="output">
                          <div class="output_area">
                            <div class="prompt">
                            </div>
                            <div class="output_text output_subarea ">
                              <pre>Intitializing Scala interpreter ...</pre>
                            </div>
                          </div>
                          <div class="output_area">
                            <div class="prompt">
                            </div>
                            <div class="output_text output_subarea ">
                              <pre>Spark Web UI available at http://10.0.2.15:4040
SparkContext available as 'sc' (version = 2.3.0, master = local[*], app id = local-1531827357926)
SparkSession available as 'spark'
</pre>
                            </div>
                          </div>
                          <div class="output_area">
                            <div class="prompt output_prompt">
                              Out[1]:
                            </div>
                            <div class="output_text output_subarea output_execute_result">
                              <pre>import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.rdd.RDD
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [2]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//comprobamos que se ha creado el objeto SparkContext</span>
<span class="n">sc</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="output_wrapper">
                        <div class="output">
                          <div class="output_area">
                            <div class="prompt output_prompt">
                              Out[2]:
                            </div>
                            <div class="output_text output_subarea output_execute_result">
                              <pre>res0: org.apache.spark.SparkContext = org.apache.spark.SparkContext@66265b45
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [3]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//se obtiene la configuración actual de SparkConf</span>
<span class="n">sc</span><span class="o">.</span><span class="n">getConf</span><span class="o">.</span><span class="n">getAll</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="output_wrapper">
                        <div class="output">
                          <div class="output_area">
                            <div class="prompt output_prompt">
                              Out[3]:
                            </div>
                            <div class="output_text output_subarea output_execute_result">
                              <pre>res1: Array[(String, String)] = Array((spark.eventLog.enabled,true), (spark.app.id,local-1531827357926), (spark.repl.class.outputDir,/tmp/tmphl2gt916), (spark.repl.class.uri,spark://10.0.2.15:44097/classes), (spark.executor.id,driver), (spark.driver.host,10.0.2.15), (spark.app.name,spylon-kernel), (spark.driver.port,44097), (spark.rdd.compress,True), (spark.eventLog.dir,/var/log/ipnb), (spark.serializer.objectStreamReset,100), (spark.master,local[*]), (spark.submit.deployMode,client), (spark.ui.showConsoleProgress,true))
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [4]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//creación de un array</span>
<span class="k">val</span> <span class="n">cadenas</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"spark"</span><span class="o">,</span> <span class="s">"hadoop"</span><span class="o">,</span> <span class="s">"hdfs"</span><span class="o">,</span> <span class="s">"spark"</span><span class="o">,</span> <span class="s">"hdfs"</span><span class="o">)</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="output_wrapper">
                        <div class="output">
                          <div class="output_area">
                            <div class="prompt output_prompt">
                              Out[4]:
                            </div>
                            <div class="output_text output_subarea output_execute_result">
                              <pre>cadenas: Array[String] = Array(spark, hadoop, hdfs, spark, hdfs)
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [5]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//creación del primer RDD mediante parallelize. </span>
<span class="c1">//indicar cantidad de nodos para paralelizar los datos.</span>
<span class="k">val</span> <span class="n">cadenasRDD</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="n">cadenas</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="output_wrapper">
                        <div class="output">
                          <div class="output_area">
                            <div class="prompt output_prompt">
                              Out[5]:
                            </div>
                            <div class="output_text output_subarea output_execute_result">
                              <pre>cadenasRDD: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[0] at parallelize at <console>:32
</console></pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [6]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//Petición de contenido con collect()</span>
<span class="c1">//Especial cuidad de llamar a collect() con RDD muy grandes.</span>
<span class="n">cadenasRDD</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="output_wrapper">
                        <div class="output">
                          <div class="output_area">
                            <div class="prompt output_prompt">
                              Out[6]:
                            </div>
                            <div class="output_text output_subarea output_execute_result">
                              <pre>res2: Array[String] = Array(spark, hadoop, hdfs, spark, hdfs)
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [7]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//declaración de RDD junto con Array.</span>
<span class="k">val</span> <span class="n">numerosRDD</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">3</span><span class="o">,</span><span class="mi">4</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="mi">6</span><span class="o">,</span><span class="mi">7</span><span class="o">,</span><span class="mi">8</span><span class="o">,</span><span class="mi">9</span><span class="o">),</span> <span class="mi">3</span><span class="o">)</span>
<span class="n">numerosRDD</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="output_wrapper">
                        <div class="output">
                          <div class="output_area">
                            <div class="prompt output_prompt">
                              Out[7]:
                            </div>
                            <div class="output_text output_subarea output_execute_result">
                              <pre>numerosRDD: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[1] at parallelize at <console>:29
res3: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9)
</console></pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [8]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//crear un RDD a partir de leer fichero desde windows</span>
<span class="k">val</span> <span class="n">file</span> <span class="k">=</span><span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">"./documentos/texto.txt"</span><span class="o">)</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="output_wrapper">
                        <div class="output">
                          <div class="output_area">
                            <div class="prompt output_prompt">
                              Out[8]:
                            </div>
                            <div class="output_text output_subarea output_execute_result">
                              <pre>file: org.apache.spark.rdd.RDD[String] = ./documentos/texto.txt MapPartitionsRDD[3] at textFile at <console>:29
</console></pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [9]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="n">file</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="output_wrapper">
                        <div class="output">
                          <div class="output_area">
                            <div class="prompt output_prompt">
                              Out[9]:
                            </div>
                            <div class="output_text output_subarea output_execute_result">
                              <pre>res4: Array[String] = Array(Esto es una prueba de un documento de texto para analizar con Spark., El perro de San Roque no tiene rabo porque Ramon Ramirez se lo ha cortado.)
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [10]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//filtrado de datos, filtra la línea que contenga la palabra Spark</span>
<span class="k">val</span> <span class="n">filtro</span> <span class="k">=</span> <span class="n">file</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">line</span> <span class="k">=></span> <span class="n">line</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="s">"perro"</span><span class="o">))</span>
<span class="n">filtro</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="output_wrapper">
                        <div class="output">
                          <div class="output_area">
                            <div class="prompt output_prompt">
                              Out[10]:
                            </div>
                            <div class="output_text output_subarea output_execute_result">
                              <pre>filtro: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[4] at filter at <console>:31
res5: Array[String] = Array(El perro de San Roque no tiene rabo porque Ramon Ramirez se lo ha cortado.)
</console></pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [11]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//devolver sólo el primer elemento</span>
<span class="n">file</span><span class="o">.</span><span class="n">first</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                      <div class="output_wrapper">
                        <div class="output">
                          <div class="output_area">
                            <div class="prompt output_prompt">
                              Out[11]:
                            </div>
                            <div class="output_text output_subarea output_execute_result">
                              <pre>res6: String = Esto es una prueba de un documento de texto para analizar con Spark.
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </hr>
          </section>
          <!-- Transformaciones
        ================================================== -->
          <section id="transformaciones">
            <div class="page-header">
              <h1>
                4. Transformaciones
              </h1>
            </div>
            <div class="codigo-scala">
              <div class="border-box-sizing" id="notebook" tabindex="-1">
                <div id="notebook-container">
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [1]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//importamos SparkConf, SparkContext, RDD</span>
<span class="k">import</span> <span class="nn">org.apache.spark.SparkConf</span> 
<span class="k">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>

<span class="c1">//creación de un array</span>
<span class="k">val</span> <span class="n">cadenas</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"spark"</span><span class="o">,</span> <span class="s">"hadoop"</span><span class="o">,</span> <span class="s">"hdfs"</span><span class="o">,</span> <span class="s">"spark"</span><span class="o">,</span> <span class="s">"hdfs"</span><span class="o">)</span>

<span class="c1">//paralelización del RDD cadenas</span>
<span class="k">val</span> <span class="n">cadenasRDD</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="n">cadenas</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt">
                          </div>
                          <div class="output_text output_subarea ">
                            <pre>Intitializing Scala interpreter ...</pre>
                          </div>
                        </div>
                        <div class="output_area">
                          <div class="prompt">
                          </div>
                          <div class="output_text output_subarea ">
                            <pre>Spark Web UI available at http://10.0.2.15:4040
SparkContext available as 'sc' (version = 2.3.0, master = local[*], app id = local-1531853649819)
SparkSession available as 'spark'
</pre>
                          </div>
                        </div>
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[1]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.rdd.RDD
cadenas: Array[String] = Array(spark, hadoop, hdfs, spark, hdfs)
cadenasRDD: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[0] at parallelize at <console>:34
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              Funciones de transformación.
                              <br>
                                map():
                              </br>
                            </strong>
                            Aplica una función a cada elemento del RDD.
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [2]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//convertir a mayúsculas cada palabra</span>
<span class="c1">//la función se leería: Para cada palabra aplicar función toUpperCase()</span>
<span class="k">val</span> <span class="n">cadenasMayusculas</span> <span class="k">=</span> <span class="n">cadenasRDD</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">palabra</span> <span class="k">=></span> <span class="n">palabra</span><span class="o">.</span><span class="n">toUpperCase</span><span class="o">())</span>
<span class="n">cadenasMayusculas</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[2]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>cadenasMayusculas: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at map at <console>:33
res0: Array[String] = Array(SPARK, HADOOP, HDFS, SPARK, HDFS)
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              filter():
                            </strong>
                            Filtra cada palabra igual a la cadena.
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [3]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">cadenasMayusculas</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">p</span> <span class="k">=></span> <span class="n">p</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="s">"ARK"</span><span class="o">))</span>
<span class="n">data</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[3]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>data: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at filter at <console>:33
res1: Array[String] = Array(SPARK, SPARK)
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              flatMap():
                            </strong>
                            Aplica una función a cada elemento y devuelve una única lista.
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [4]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="k">val</span> <span class="n">mayusculas</span> <span class="k">=</span> <span class="n">cadenasRDD</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="n">p</span> <span class="k">=></span> <span class="n">p</span><span class="o">.</span><span class="n">toUpperCase</span><span class="o">())</span>
<span class="n">mayusculas</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[4]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>mayusculas: org.apache.spark.rdd.RDD[Char] = MapPartitionsRDD[3] at flatMap at <console>:31
res2: Array[Char] = Array(S, P, A, R, K, H, A, D, O, O, P, H, D, F, S, S, P, A, R, K, H, D, F, S)
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [5]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="k">val</span> <span class="n">mayusLength</span> <span class="k">=</span> <span class="n">cadenasRDD</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="n">p</span> <span class="k">=></span> <span class="nc">List</span><span class="o">(</span><span class="n">p</span><span class="o">.</span><span class="n">toUpperCase</span><span class="o">(),</span> <span class="n">p</span><span class="o">.</span><span class="n">length</span><span class="o">))</span>
<span class="n">mayusLength</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[5]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>mayusLength: org.apache.spark.rdd.RDD[Any] = MapPartitionsRDD[4] at flatMap at <console>:31
res3: Array[Any] = Array(SPARK, 5, HADOOP, 6, HDFS, 4, SPARK, 5, HDFS, 4)
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              union():
                            </strong>
                            une RDDs.
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [6]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="k">val</span> <span class="n">cadenasBoth</span> <span class="k">=</span> <span class="n">cadenasRDD</span><span class="o">.</span><span class="n">union</span><span class="o">(</span><span class="n">cadenasMayusculas</span><span class="o">)</span>
<span class="n">cadenasBoth</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[6]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>cadenasBoth: org.apache.spark.rdd.RDD[String] = UnionRDD[5] at union at <console>:33
res4: Array[String] = Array(spark, hadoop, hdfs, spark, hdfs, SPARK, HADOOP, HDFS, SPARK, HDFS)
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              distinct():
                            </strong>
                            elimina valores repetidos.
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [7]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="n">cadenasBoth</span><span class="o">.</span><span class="n">distinct</span><span class="o">().</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[7]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>res5: Array[String] = Array(hadoop, SPARK, hdfs, spark, HDFS, HADOOP)
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              groupByKey():
                            </strong>
                            Agrupa por cada key única los valor.
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [8]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//se crea un RDD de pares clave valor.</span>
<span class="k">val</span> <span class="n">parCV</span> <span class="k">=</span> <span class="n">cadenasRDD</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">p</span> <span class="k">=></span> <span class="o">(</span><span class="n">p</span><span class="o">,</span><span class="mi">1</span><span class="o">))</span>
<span class="n">parCV</span><span class="o">.</span><span class="n">collect</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[8]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>parCV: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[9] at map at <console>:32
res6: Array[(String, Int)] = Array((spark,1), (hadoop,1), (hdfs,1), (spark,1), (hdfs,1))
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [9]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//se aplica groupByKey donde se realiza un agregado de claves por cada valor único </span>
<span class="k">val</span> <span class="n">group</span> <span class="k">=</span> <span class="n">parCV</span><span class="o">.</span><span class="n">groupByKey</span><span class="o">()</span>
<span class="n">group</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[9]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>group: org.apache.spark.rdd.RDD[(String, Iterable[Int])] = ShuffledRDD[10] at groupByKey at <console>:34
res7: Array[(String, Iterable[Int])] = Array((hadoop,CompactBuffer(1)), (hdfs,CompactBuffer(1, 1)), (spark,CompactBuffer(1, 1)))
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              reduceByKey():
                            </strong>
                            Realiza una agrupación por clave única y reduce los valores de cada clave.
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [10]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//(_+_) indica sumar todos los valores</span>
<span class="c1">//(_+_) se puede expresar también como ((a,b) => a+b)</span>
<span class="k">val</span> <span class="n">suma</span> <span class="k">=</span> <span class="n">parCV</span><span class="o">.</span><span class="n">reduceByKey</span><span class="o">(</span><span class="k">_</span> <span class="o">+</span> <span class="k">_</span><span class="o">)</span>
<span class="n">suma</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[10]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>suma: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[11] at reduceByKey at <console>:35
res8: Array[(String, Int)] = Array((hadoop,1), (hdfs,2), (spark,2))
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              sortByKey():
                            </strong>
                            Ordena por clave.
true: orden ascendente
false: orden descendente
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [11]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="n">parCV</span><span class="o">.</span><span class="n">sortByKey</span><span class="o">(</span><span class="kc">false</span><span class="o">).</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[11]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>res9: Array[(String, Int)] = Array((spark,1), (spark,1), (hdfs,1), (hdfs,1), (hadoop,1))
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              crear una función para pasarla a un map:
                            </strong>
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [12]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//se crea la función con parámetro de entrada string y devuelve un string y un entero.</span>
<span class="k">def</span> <span class="n">tamanyo</span><span class="o">(</span><span class="n">s</span> <span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="k">return</span><span class="o">(</span><span class="n">s</span><span class="o">,</span> <span class="n">s</span><span class="o">.</span><span class="n">length</span><span class="o">());</span>
<span class="o">}</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[12]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>tamanyo: (s: String)(String, Int)
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [13]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="n">cadenasRDD</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">tamanyo</span><span class="o">(</span><span class="k">_</span><span class="o">)).</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[13]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>res10: Array[(String, Int)] = Array((spark,5), (hadoop,6), (hdfs,4), (spark,5), (hdfs,4))
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>
          <section id="acciones">
            <div class="page-header">
              <h1>
                5. Acciones
              </h1>
            </div>
            <div class="codigo-scala">
              <div class="border-box-sizing" id="notebook" tabindex="-1">
                <div id="notebook-container">
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [1]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//importamos SparkConf, SparkContext, RDD</span>
<span class="k">import</span> <span class="nn">org.apache.spark.SparkConf</span> 
<span class="k">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>

<span class="c1">//creación de un array</span>
<span class="k">val</span> <span class="n">cadenas</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"spark"</span><span class="o">,</span> <span class="s">"hadoop"</span><span class="o">,</span> <span class="s">"hdfs"</span><span class="o">,</span> <span class="s">"spark"</span><span class="o">,</span> <span class="s">"hdfs"</span><span class="o">)</span>

<span class="c1">//paralelización del RDD cadenas</span>
<span class="k">val</span> <span class="n">cadenasRDD</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="n">cadenas</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>

<span class="c1">//declaración y paralelización de RDD</span>
<span class="k">val</span> <span class="n">numerosRDD</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">3</span><span class="o">,</span><span class="mi">4</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="mi">6</span><span class="o">,</span><span class="mi">7</span><span class="o">,</span><span class="mi">8</span><span class="o">,</span><span class="mi">9</span><span class="o">),</span> <span class="mi">3</span><span class="o">)</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt">
                          </div>
                          <div class="output_text output_subarea ">
                            <pre>Intitializing Scala interpreter ...</pre>
                          </div>
                        </div>
                        <div class="output_area">
                          <div class="prompt">
                          </div>
                          <div class="output_text output_subarea ">
                            <pre>Spark Web UI available at http://10.0.2.15:4041
SparkContext available as 'sc' (version = 2.3.0, master = local[*], app id = local-1531858672993)
SparkSession available as 'spark'
</pre>
                          </div>
                        </div>
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[1]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.rdd.RDD
cadenas: Array[String] = Array(spark, hadoop, hdfs, spark, hdfs)
cadenasRDD: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[0] at parallelize at <console>:34
numerosRDD: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[1] at parallelize at <console>:37
</console></console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              colect()
                            </strong>
                            muestra el contenido de un RDD contenido
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [2]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="n">cadenasRDD</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[2]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>res0: Array[String] = Array(spark, hadoop, hdfs, spark, hdfs)
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              first()
                            </strong>
                            devuelve el primer elemento de un RDD
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [3]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="n">cadenasRDD</span><span class="o">.</span><span class="n">first</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[3]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>res1: String = spark
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              count()
                            </strong>
                            devuelve el número de elemento de un RDD
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [4]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="n">cadenasRDD</span><span class="o">.</span><span class="n">count</span><span class="o">()</span> <span class="o">+</span> <span class="n">numerosRDD</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[4]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>res2: Long = 14
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              reduce()
                            </strong>
                            Aplica una acción a todos los elementos del RDD y devuelve un único elemento
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [5]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//aplicar reduce con la suma de los elementos contenidos en numerosRDD</span>
<span class="n">numerosRDD</span><span class="o">.</span><span class="n">reduce</span><span class="o">(</span><span class="k">_</span><span class="o">+</span><span class="k">_</span><span class="o">)</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[5]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>res3: Int = 45
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              take()
                            </strong>
                            devuelve n primeros elementos del RDD
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [6]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="n">numerosRDD</span><span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[6]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>res4: Array[Int] = Array(1, 2, 3)
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              max()
                            </strong>
                            devuelve el número máximo de entre los elementos del RDD
                            <strong>
                              min()
                            </strong>
                            devuelve el número mínimo de entre los elementos del RDD
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [7]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="n">numerosRDD</span><span class="o">.</span><span class="n">max</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[7]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>res5: Int = 9
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              countByKey()
                            </strong>
                            devuelve el conteo de valores para cada única clave
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [8]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//se crea un RDD de pares clave valor.</span>
<span class="k">val</span> <span class="n">parCV</span> <span class="k">=</span> <span class="n">cadenasRDD</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">p</span> <span class="k">=></span> <span class="o">(</span><span class="n">p</span><span class="o">,</span><span class="mi">1</span><span class="o">))</span>
<span class="n">parCV</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[8]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>parCV: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[2] at map at <console>:32
res6: Array[(String, Int)] = Array((spark,1), (hadoop,1), (hdfs,1), (spark,1), (hdfs,1))
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [9]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="n">parCV</span><span class="o">.</span><span class="n">countByKey</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[9]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>res7: scala.collection.Map[String,Long] = Map(hadoop -> 1, hdfs -> 2, spark -> 2)
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <hr>
                          <p>
                            <strong>
                              foreach()
                            </strong>
                            aplicar una acción por cada elemento del RDD
                          </p>
                        </hr>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [10]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="n">cadenasRDD</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">p</span> <span class="k">=></span> <span class="n">println</span><span class="o">(</span><span class="s">"La palabra es "</span> <span class="o">+</span> <span class="n">p</span><span class="o">))</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt">
                          </div>
                          <div class="output_subarea output_stream output_stdout output_text">
                            <pre>La palabra es hadoop
La palabra es hdfs
La palabra es spark
La palabra es spark
La palabra es hdfs
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>
          <section id="persistencia-head">
            <div class="page-header">
              <h1>
                6. Persistencia y acumuladores
              </h1>
            </div>
            <p>
              Spark tiene evaluación perezosa.
            </p>
            <p>
              Puede ser necesario utilizar un RDD varias veces y para evitar el coste de tener que recalcular continuamente el RDD se utiliza la
              <strong>
                persistencia.
              </strong>
            </p>
            <p>
              Cuando se persiste un dato cada nodo es el responsable de almacenar internamente su parte.
            </p>
            <p>
              Si un nodo con datos persistentes falla, Spark recalcula las particiones perdidas cuando sea necesario.
            </p>
            <p>
              Existen varios niveles de persistencia pudiendo especificar que Spark
              <strong>
                serialice o no los datos en disco, memoria o una combinación de ambas.
              </strong>
            </p>
            <ul>
              <strong>
                Tipos de persistencia
              </strong>
              <li>
                <strong>
                  MEMORY_ONLY
                </strong>
                : Sólo memoria
              </li>
              <li>
                <strong>
                  MEMORY_AND_DISK
                </strong>
                : Memoria y disco
              </li>
              <li>
                <strong>
                  MEMORY_AND_DISK_SER
                </strong>
                : Memoria y disco serializado
              </li>
              <li>
                <strong>
                  DISK_ONLY
                </strong>
                : Sólo disco
              </li>
              <li>
                <strong>
                  MEMORY_ONLY_SER
                </strong>
                : Sólo memoria serializada
              </li>
              <li>
                <strong>
                  MEMORY_ONLY_2
                </strong>
                : Sólo memoria (versión mejorada)
              </li>
            </ul>
            <p>
              Si la persistencia de datos excede la memoria disponible Spark despreciará automáticamente las particiones más antíguas.
            </p>
            <div class="scala-codigo">
              <div class="border-box-sizing" id="notebook" tabindex="-1">
                <div id="notebook-container">
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [1]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//importamos SparkConf, SparkContext, RDD, nivel de persistencia</span>
<span class="k">import</span> <span class="nn">org.apache.spark.SparkConf</span> 
<span class="k">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>
<span class="k">import</span> <span class="nn">org.apache.spark.storage.StorageLevel</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt">
                          </div>
                          <div class="output_text output_subarea ">
                            <pre>Intitializing Scala interpreter ...</pre>
                          </div>
                        </div>
                        <div class="output_area">
                          <div class="prompt">
                          </div>
                          <div class="output_text output_subarea ">
                            <pre>Spark Web UI available at http://10.0.2.15:4040
SparkContext available as 'sc' (version = 2.3.0, master = local[*], app id = local-1532079923831)
SparkSession available as 'spark'
</pre>
                          </div>
                        </div>
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[1]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.rdd.RDD
import org.apache.spark.storage.StorageLevel
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [2]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="k">val</span> <span class="n">fileMemory</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">"./documentos/persistenciaFile"</span><span class="o">)</span>

<span class="c1">//persistencia de los datos en memoria</span>
<span class="n">fileMemory</span><span class="o">.</span><span class="n">persist</span><span class="o">(</span><span class="nc">StorageLevel</span><span class="o">.</span><span class="nc">MEMORY_ONLY</span><span class="o">)</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[2]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>fileMemory: org.apache.spark.rdd.RDD[String] = ./documentos/persistenciaFile MapPartitionsRDD[1] at textFile at <console>:29
res0: fileMemory.type = ./documentos/persistenciaFile MapPartitionsRDD[1] at textFile at <console>:29
</console></console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [3]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//se pone a prueba el tiempo de cálculo con los datos persistidos en memoria.</span>

<span class="c1">//variable tiempo de inicio.</span>
<span class="k">val</span> <span class="n">timestampInicio</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="n">currentTimeMillis</span>

<span class="c1">//filtrado de palabras con tamaño mayor que 6.</span>
<span class="k">val</span> <span class="n">mayor6</span> <span class="k">=</span> <span class="n">fileMemory</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="n">x</span> <span class="k">=></span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">" "</span><span class="o">))</span>
<span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">p</span> <span class="k">=></span> <span class="n">p</span><span class="o">.</span><span class="n">length</span> <span class="o">></span> <span class="mi">6</span><span class="o">)</span>

<span class="c1">//se realiza una acción para obligar a realizar el cálculo.</span>
<span class="n">mayor6</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>

<span class="c1">//variable tiempo final</span>
<span class="k">val</span> <span class="n">timestampFin</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="nc">System</span><span class="o">.</span><span class="n">currentTimeMillis</span>

<span class="n">println</span><span class="o">(</span><span class="s">" Tiempo "</span> <span class="o">+</span> <span class="o">(</span><span class="n">timestampFin</span> <span class="o">-</span> <span class="n">timestampInicio</span><span class="o">))</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt">
                          </div>
                          <div class="output_subarea output_stream output_stdout output_text">
                            <pre> Tiempo 1166
</pre>
                          </div>
                        </div>
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[3]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>timestampInicio: Long = 1532079941254
mayor6: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[3] at filter at <console>:38
timestampFin: Long = 1532079942420
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [4]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//se elimina la persistencia actual</span>
<span class="n">fileMemory</span><span class="o">.</span><span class="n">unpersist</span><span class="o">()</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[4]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>res2: fileMemory.type = ./documentos/persistenciaFile MapPartitionsRDD[1] at textFile at <console>:29
</console></pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing text_cell rendered">
                    <div class="prompt input_prompt">
                    </div>
                    <div class="inner_cell">
                      <div class="text_cell_render border-box-sizing rendered_html">
                        <p>
                          <hr/>
                        </p>
                        <h4 id="Acumuladores:">
                          Acumuladores:
                          <a class="anchor-link" href="#Acumuladores:">
                          </a>
                        </h4>
                        <ul>
                          <li>
                            Son variables compartidas de tipo int o double.
                          </li>
                          <li>
                            Se crean a partir de un sparkContext "sc".
                          </li>
                          <li>
                            Sólo el driver puede acceder al valor, los accesos desde workers devuelven error.
                          </li>
                          <li>
                            Los workers sólo pueden incrementar el valor.
                          </li>
                        </ul>
                      </div>
                    </div>
                  </div>
                  <div class="cell border-box-sizing code_cell rendered">
                    <div class="input">
                      <div class="prompt input_prompt">
                        In [5]:
                      </div>
                      <div class="inner_cell">
                        <div class="input_area">
                          <div class=" highlight hl-scala">
                            <pre><span></span><span class="c1">//creación de un acumulable de tipo long.</span>
<span class="k">val</span> <span class="n">accum</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">longAccumulator</span><span class="o">(</span><span class="s">"NumPalabras"</span><span class="o">)</span>

<span class="c1">//para cada palabra en mayor6 suma 1. (vendría a ser como un count())</span>
<span class="n">mayor6</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">p</span> <span class="k">=></span> <span class="n">accum</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>

<span class="c1">//consulta del valor acumulado (la variable es de tipo global)</span>
<span class="c1">//este valor también se puede consultar desde los jobs de Spark, localhost:4040/jobs</span>
<span class="n">accum</span><span class="o">.</span><span class="n">value</span>
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="output_wrapper">
                      <div class="output">
                        <div class="output_area">
                          <div class="prompt output_prompt">
                            Out[5]:
                          </div>
                          <div class="output_text output_subarea output_execute_result">
                            <pre>accum: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 26, name: Some(NumPalabras), value: 5140)
res3: Long = 5140
</pre>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>
          <!-- RDD, Dataframe y Dataset
        ================================================== -->
          <section id="dataframe-dataset">
            <div class="page-header">
              <h1>
                7. Dataframe - Datasets
              </h1>
              <div class="codigo-scala">
                <div class="border-box-sizing" id="notebook" tabindex="-1">
                  <div id="notebook-container">
                    <div class="cell border-box-sizing text_cell rendered">
                      <div class="prompt input_prompt">
                      </div>
                      <div class="inner_cell">
                        <div class="text_cell_render border-box-sizing rendered_html">
                          <h2 id="Datasets">
                            Datasets
                            <a class="anchor-link" href="#Datasets">
                            </a>
                          </h2>
                          <p>
                            <strong>
                              Dataset:
                            </strong>
                            Colección de datos con estructura.
                          </p>
                          <ul>
                            <li>
                              Poseen los beneficios de los RDD
                            </li>
                            <li>
                              Evaluación perezosa
                            </li>
                            <li>
                              API para Scala y Java
                            </li>
                          </ul>
                          <h2 id="Dataframe">
                            Dataframe
                            <a class="anchor-link" href="#Dataframe">
                            </a>
                          </h2>
                          <p>
                            <strong>
                              Dataframe:
                            </strong>
                            Colección de datos con estructura organizado en columnas.
                          </p>
                          <h2 id="SparkSession">
                            SparkSession
                            <a class="anchor-link" href="#SparkSession">
                            </a>
                          </h2>
                          <p>
                            <strong>
                              SparkSession:
                            </strong>
                            Se utilizan para crear
                            <strong>
                              dataset y dataframe
                            </strong>
                            al igual que se utiliza
                            <strong>
                              SparkContext
                            </strong>
                            para crear
                            <strong>
                              RDD
                            </strong>
                            .
                          </p>
                          <p>
                            //creación de SparkSession
val spark = SparkSession.builder()
                          </p>
                          <hr>
                          </hr>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing text_cell rendered">
                      <div class="prompt input_prompt">
                      </div>
                      <div class="inner_cell">
                        <div class="text_cell_render border-box-sizing rendered_html">
                          <h2 id="Dataframes">
                            Dataframes
                            <a class="anchor-link" href="#Dataframes">
                            </a>
                          </h2>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [ ]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>

<span class="c1">//creación de una SparkSession incluyendo algunas configuraciones.</span>
<span class="c1">// appName: Nombre de la Aplicación</span>
<span class="c1">// master: maquina donde se va a ejecutar</span>
<span class="c1">// getOrCreate: Si existe devuelve sesión anterior sino crea una nueva.</span>
<span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">"miApp"</span><span class="o">).</span><span class="n">master</span><span class="o">(</span><span class="s">"local"</span><span class="o">).</span><span class="n">getOrCreate</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [ ]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//leer fichero json y convertirlo en dataframe</span>
<span class="k">val</span> <span class="n">characters</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="s">"./documentos/strangersCharacters.json"</span><span class="o">)</span>

<span class="c1">//show(): mostrar el contenido del dataframe</span>
<span class="n">characters</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [ ]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//ver la estructura del dataframe</span>
<span class="n">characters</span><span class="o">.</span><span class="n">columns</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [ ]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//imprimir el schema</span>
<span class="n">characters</span><span class="o">.</span><span class="n">printSchema</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [ ]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//seleccionar columnas</span>
<span class="k">val</span> <span class="n">nombres</span> <span class="k">=</span> <span class="n">characters</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">"nombre"</span><span class="o">,</span> <span class="s">"edad"</span><span class="o">)</span>
<span class="n">nombres</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [ ]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//filtrar personajes con edad menor a 15 años</span>
<span class="c1">//$ selecciona la columna</span>
<span class="k">val</span> <span class="n">children</span> <span class="k">=</span> <span class="n">characters</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">"edad"</span> <span class="o"><</span> <span class="mi">15</span><span class="o">)</span>
<span class="n">children</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [ ]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">// primer elemento</span>
<span class="n">children</span><span class="o">.</span><span class="n">first</span><span class="o">()</span>

<span class="c1">//los 5 primeros elementos</span>
<span class="n">children</span><span class="o">.</span><span class="n">head</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>

<span class="c1">//contar elementos</span>
<span class="n">children</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>

<span class="c1">//agrupar por edad</span>
<span class="n">characters</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="s">"edad"</span><span class="o">).</span><span class="n">count</span><span class="o">().</span><span class="n">show</span><span class="o">()</span>

<span class="c1">//discribe inspecciona los resultados</span>
<span class="n">characters</span><span class="o">.</span><span class="n">describe</span><span class="o">().</span><span class="n">show</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing text_cell rendered">
                      <div class="prompt input_prompt">
                      </div>
                      <div class="inner_cell">
                        <div class="text_cell_render border-box-sizing rendered_html">
                          <h2 id="Datasets">
                            Datasets
                            <a class="anchor-link" href="#Datasets">
                            </a>
                          </h2>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing text_cell rendered">
                      <div class="prompt input_prompt">
                      </div>
                      <div class="inner_cell">
                        <div class="text_cell_render border-box-sizing rendered_html">
                          <p>
                            import org.apache.spark.sql.SparkSession</p>
<p>val spark = SparkSession.builder.appName("miApp").master("local").getOrCreate()
                          </p>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [ ]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//Carga de fichero en RDD invocando a SparkContext</span>
<span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>
<span class="k">val</span> <span class="n">text</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">"documentos/strangersCharacters.txt"</span><span class="o">)</span>

<span class="c1">//se crea la clase personaje para posteriormente asignarselo a text.</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">Personaje</span><span class="o">(</span><span class="n">nombre</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">edad</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">sexo</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span>

<span class="c1">//Siempre que se trabaje con dataset se ha de importar spark.implicits._</span>
<span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">//se importa Row para trabajar con filas.</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.Row</span>

<span class="c1">//separación de palabras por comas.</span>
<span class="k">val</span> <span class="n">partes</span> <span class="k">=</span> <span class="n">text</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">","</span><span class="o">))</span>
<span class="n">partes</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [ ]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//convertir partes a objeto de tipo personajes.</span>
<span class="c1">//con la función map se recorre cada uno de los arrays y se crea una clase personaje.</span>
<span class="c1">//con trim se eliminan los espacios por delante y por detrás.  </span>

<span class="k">val</span> <span class="n">personajes</span> <span class="k">=</span> <span class="n">partes</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">atr</span> <span class="k">=></span> <span class="nc">Personaje</span><span class="o">(</span><span class="n">atr</span><span class="o">(</span><span class="mi">0</span><span class="o">),</span> <span class="n">atr</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">trim</span><span class="o">.</span><span class="n">toInt</span><span class="o">,</span> <span class="n">atr</span><span class="o">(</span><span class="mi">2</span><span class="o">))).</span><span class="n">toDS</span><span class="o">()</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                    <div class="cell border-box-sizing code_cell rendered">
                      <div class="input">
                        <div class="prompt input_prompt">
                          In [ ]:
                        </div>
                        <div class="inner_cell">
                          <div class="input_area">
                            <div class=" highlight hl-scala">
                              <pre><span></span><span class="c1">//filtrar datos por edad</span>
<span class="n">personajes</span><span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">"edad"</span> <span class="o">></span><span class="mi">13</span><span class="o">)</span>

<span class="c1">//personaje con la máxima edad</span>
<span class="n">personajes</span><span class="o">.</span><span class="n">agg</span><span class="o">(</span><span class="n">max</span><span class="o">(</span><span class="n">$</span><span class="s">"edad"</span><span class="o">))</span>

<span class="c1">//seleccionar los 5 primeros personajes en formato lista.</span>
<span class="n">personajes</span><span class="o">.</span><span class="n">takeAsList</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>

<span class="c1">//pasar de dataset a dataframe</span>
<span class="k">val</span> <span class="n">personajesDF</span> <span class="k">=</span> <span class="n">personajes</span><span class="o">.</span><span class="n">toDF</span><span class="o">(</span><span class="s">"nombre"</span><span class="o">,</span> <span class="s">"edad"</span><span class="o">,</span> <span class="s">"sexo"</span><span class="o">)</span>

<span class="c1">//pasar de dataset a RDD</span>
<span class="n">personajes</span><span class="o">.</span><span class="n">rdd</span>

<span class="c1">//volcar el contenido de dataset a fichero</span>
<span class="k">val</span> <span class="n">nombreEdad</span> <span class="k">=</span> <span class="n">personajesDF</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">"nombre"</span><span class="o">,</span><span class="s">"edad"</span><span class="o">)</span>

<span class="c1">//guardado en formato parquet</span>
<span class="n">nombreEdad</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">save</span><span class="o">(</span><span class="s">"/Ejercicios/documentos/personajesParquet"</span><span class="o">)</span>

<span class="c1">//guardado en formato json</span>
<span class="n">nombreEdad</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">save</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="s">"/Ejercicios/documentos/personajesJSON"</span><span class="o">)</span>
</pre>
                            </div>
                          </div>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>
          <section id="vistas">
            <div class="page-header">
              <h1>
                8. Vistas
              </h1>
            </div>
            <ul>
              <li>Las <strong>Vistas</strong> permiten lanzar <strong>consultas SQL</strong> sobre los<strong> DataFrame</strong></li>
              <li>Existen Vistas <strong>Temporales y Globales</strong> </li>
            </ul>
            <hr>
            <p><strong>Vistas Temporales:</strong></p>
            <ul>
              <li>Disponible únicamente en la sesión donde se crea.</li>
              <li>Se ha de asignar un nombre a la <strong>Vista</strong> que será el <strong>nombre de la tabla</strong></li>
            </ul>
            <p>df.createOrReplaceTempview("nombre")</p>
            <hr>
            <p><strong>Vistas Globales:</strong></p>
            <ul>
              <li>Disponible en nuevas sesiones.</li>
              <li>Se consulta añadiendo <strong>global_temp</strong> antes del nombre</li>
            </ul>
            <p>df.createOrReplaceTempview("people")</p>
            <p>spark.sql("SELECT * FROM global_temp.people")</p>
            <hr>
            <div class="codigo-scala">
              <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Vistas-temporales:">Vistas temporales:<a class="anchor-link" href="#Vistas-temporales:"></a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span><span class="c1">// carga de fichero</span>
<span class="k">val</span> <span class="n">tweetJson</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="s">&quot;./documentos/large-17-json&quot;</span><span class="o">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Intitializing Scala interpreter ...</pre>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_text output_subarea ">
<pre>Spark Web UI available at http://10.0.2.15:4040
SparkContext available as &#39;sc&#39; (version = 2.3.0, master = local[*], app id = local-1532257222616)
SparkSession available as &#39;spark&#39;
</pre>
</div>

</div>

<div class="output_area">

<div class="prompt output_prompt">Out[1]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>tweetJson: org.apache.spark.sql.DataFrame = [contributors: string, coordinates: struct&lt;coordinates: array&lt;double&gt;, type: string&gt; ... 22 more fields]
</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span><span class="c1">// crear Vista</span>
<span class="n">tweetJson</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;tweets&quot;</span><span class="o">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span><span class="k">val</span> <span class="n">usuarios</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT user.screen_name FROM tweets WHERE user.followers_count &gt; 300000&quot;</span><span class="o">)</span>
<span class="n">usuarios</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>+--------------+
|   screen_name|
+--------------+
|   SpeakComedy|
|      AnnCurry|
|      AnnCurry|
|       BBCNews|
|           CNN|
|       AndyBVB|
|   TPO_Hisself|
|          TIME|
|HuffingtonPost|
|     ObamaNews|
|   TPO_Hisself|
|       gmanews|
|     wikileaks|
|     nikestore|
|       Foro_TV|
|          Wale|
|      politico|
| DRUDGE_REPORT|
|   UniNoticias|
|      sherlyny|
+--------------+
only showing top 20 rows

</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[11]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>usuarios: org.apache.spark.sql.DataFrame = [screen_name: string]
</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span><span class="c1">// buscar tweets en español con mayor número de hashtags</span>
<span class="k">val</span> <span class="n">tweetsSpanish</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT created_at, user.name, entities.hashtags.text FROM tweets WHERE lang = &#39;es&#39; AND size(entities.hashtags.text) &gt; 0&quot;</span><span class="o">);</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[13]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>tweetsSpanish: org.apache.spark.sql.DataFrame = [created_at: string, name: string ... 1 more field]
</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span><span class="n">tweetsSpanish</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>+--------------------+--------------------+--------------------+
|          created_at|                name|                text|
+--------------------+--------------------+--------------------+
|Fri Dec 21 22:53:...|           elbabas11|            [currar]|
|Fri Dec 21 22:53:...|         GO HEAD GUY|                [FF]|
|Fri Dec 21 22:53:...|                    |                [ff]|
|Fri Dec 21 22:53:...|                 *.*|[culpadelbaktúnmaya]|
|Fri Dec 21 22:54:...|      MIL PALABRAS. |      [buenasnoches]|
|Fri Dec 21 22:54:...|       soy un arroz-|  [PaRomeoConSuperQ]|
|Fri Dec 21 22:54:...|         Over Again♥|           [Imagina]|
|Fri Dec 21 22:54:...|   Diario Estrategia|[AHORA, abismofis...|
|Fri Dec 21 22:54:...|           Jon Ayala|[TuitUtil, FF, Tu...|
|Fri Dec 21 22:54:...|       A.C. New Camp|        [soundcloud]|
|Fri Dec 21 22:54:...|              Emilia|      [FF, TuitUtil]|
|Fri Dec 21 22:54:...|           Cupcake ღ|      [FF, TuitUtil]|
|Fri Dec 21 22:54:...|     Nelson Barroeta|              [loba]|
|Fri Dec 21 22:54:...|         rocio malik|[siyofuerasantacl...|
|Fri Dec 21 22:54:...|               jonny|     [MartesDeTetas]|
|Fri Dec 21 22:54:...|              Aldi †|   [EstoyComoQuiero]|
|Fri Dec 21 22:54:...|      Lucía Luaces ♥|       [VALDOVELVET]|
|Fri Dec 21 22:54:...|      Elena Iglesias|      [feliznavidad]|
|Fri Dec 21 22:54:...|        ♬Hinojosa ⑨™|      [FF, TuitUtil]|
|Fri Dec 21 22:54:...|            Ifigenia|[cancionesdeAgüitas]|
+--------------------+--------------------+--------------------+
only showing top 20 rows

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Vistas-globales:">Vistas globales:<a class="anchor-link" href="#Vistas-globales:"></a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span><span class="c1">// se crea una nueva sesión</span>
<span class="k">val</span> <span class="n">spark2</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">newSession</span><span class="o">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[17]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>spark2: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@1b8be9e9
</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span><span class="n">tweetJson</span><span class="o">.</span><span class="n">createOrReplaceGlobalTempView</span><span class="o">(</span><span class="s">&quot;tweets_global&quot;</span><span class="o">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span><span class="n">spark2</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT * FROM global_temp.tweets_global&quot;</span><span class="o">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[25]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>res17: org.apache.spark.sql.DataFrame = [contributors: string, coordinates: struct&lt;coordinates: array&lt;double&gt;, type: string&gt; ... 22 more fields]
</pre>
</div>

</div>

</div>
</div>

</div>
    </div>
  </div>
            </div>
           </section>  
        </div>
      </div>
    </div>
    <!-- Footer
    ================================================== -->
    <footer class="footer">
      <div class="container">
        <p>
          Roberto Caride,
          <a href="mailto:forraxa@gmail.com">
            forraxa@gmail.com
          </a>
        </p>
        <p>
          <a href="https://www.youtube.com/channel/UCI1EBKWrqdVqcGMlbLVSYjA?view_as=subscriber" target="_blank">
            Canal youtube
          </a>
        </p>
      </div>
    </footer>
    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="http://platform.twitter.com/widgets.js" type="text/javascript">
    </script>
    <script src="assets/js/jquery.js">
    </script>
    <script src="assets/js/bootstrap-transition.js">
    </script>
    <script src="assets/js/bootstrap-alert.js">
    </script>
    <script src="assets/js/bootstrap-modal.js">
    </script>
    <script src="assets/js/bootstrap-dropdown.js">
    </script>
    <script src="assets/js/bootstrap-scrollspy.js">
    </script>
    <script src="assets/js/bootstrap-tab.js">
    </script>
    <script src="assets/js/bootstrap-tooltip.js">
    </script>
    <script src="assets/js/bootstrap-popover.js">
    </script>
    <script src="assets/js/bootstrap-button.js">
    </script>
    <script src="assets/js/bootstrap-collapse.js">
    </script>
    <script src="assets/js/bootstrap-carousel.js">
    </script>
    <script src="assets/js/bootstrap-typeahead.js">
    </script>
    <script src="assets/js/bootstrap-affix.js">
    </script>
    <script src="assets/js/holder/holder.js">
    </script>
    <script src="assets/js/google-code-prettify/prettify.js">
    </script>
    <script src="assets/js/application.js">
    </script>
    <!-- Analytics
    ================================================== -->
    <script>
      var _gauges = _gauges || [];
      (function() {
        var t   = document.createElement('script');
        t.type  = 'text/javascript';
        t.async = true;
        t.id    = 'gauges-tracker';
        t.setAttribute('data-site-id', '4f0dc9fef5a1f55508000013');
        t.src = '//secure.gaug.es/track.js';
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(t, s);
      })();
    </script>
  </body>
</html>
